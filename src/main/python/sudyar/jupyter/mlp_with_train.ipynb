{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (20,6)\n",
    "rng = np.random.default_rng(51)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Функции активации и их дифференциал"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "  return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def dsigmoid(x):\n",
    "  return sigmoid(x) * (1 - sigmoid(x))\n",
    "\n",
    "\n",
    "def simpl_f(x):\n",
    "  res = np.copy(x)\n",
    "  res[res >= 0] = 1\n",
    "  res[res < 0 ] = 0\n",
    "  return res\n",
    "\n",
    "\n",
    "def tanh(x):\n",
    "  return np.tanh(x)\n",
    "\n",
    "def dtanh(x):\n",
    "  return 1 - np.square(tanh(x))\n",
    "\n",
    "# Средняя квадратичная ошибка\n",
    "def mse(y_pred, y):\n",
    "  # 1/n*sum((угаданное-Y)^2)\n",
    "  err = np.mean(np.square(y_pred - y))\n",
    "  return err\n",
    "\n",
    "# y_pred - рассчитанное значение, y - ожидаемое\n",
    "def dmse(y_pred, y):\n",
    "  n = y.shape[0]\n",
    "  return (2/n)*(y_pred - y)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Класс модели"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "class MLP:\n",
    "  def __init__(self, architecture, lr=0.01, is_need_f_final=False, fn=(sigmoid, dsigmoid)):\n",
    "    self.depth = len(architecture) - 1\n",
    "    self.lamda = lr\n",
    "    # Требуется ли активационная функция на выходном слое\n",
    "    self._is_need_func_final = is_need_f_final\n",
    "\n",
    "    self.activation_fn = fn[0]\n",
    "    self.activation_dfn = fn[1]\n",
    "\n",
    "    self.error_fn = mse\n",
    "    self.error_dfn = dmse\n",
    "\n",
    "    # Веса (k, i, j - k: номер слоя 0 = первый скрытый слой; i - конкретный нейрон; j - нейрон предыдущего слоя)\n",
    "    self.W = self._init_weights(architecture)\n",
    "    # Смещение (или порог активации)\n",
    "    # (k, i, j - k: номер слоя 0 = первый скрытый слой; i - конкретный нейрон; j=1)\n",
    "    self.b = self._init_biases(architecture)\n",
    "\n",
    "\n",
    "# Прямое направление\n",
    "    # Сумматор\n",
    "    self.z = [None] * (self.depth+1)\n",
    "    # Результат функции активации (кроме последнего слоя) (k: номер слоя: 0 - вход, 1 - первый скрытый слой; j количество нейронов на слое; l - количество данных на батч\n",
    "    self.a = [None] * (self.depth+1)\n",
    "\n",
    "    #Дельта правило (при инициализации заполняются 0)\n",
    "    self.dW = [np.zeros_like(w) for w in self.W]\n",
    "    self.db = [np.zeros_like(b) for b in self.b]\n",
    "\n",
    "    # glorot uniform init\n",
    "  def _init_weights(self, arch):\n",
    "    net_in = arch[0]\n",
    "    net_out = arch[-1]\n",
    "    limit = np.sqrt(6. / (net_in + net_out))\n",
    "    return [rng.uniform(-limit, limit + 1e-5, size=(arch[i+1], arch[i])) for i in range(self.depth)]\n",
    "\n",
    "  def _init_biases(self, arch):\n",
    "    return [rng.random((arch[i+1],1))*2-1 for i in range(self.depth)]\n",
    "\n",
    "  def set_weights(self, new_W):\n",
    "    self.W = new_W\n",
    "\n",
    "  def set_biases(self, new_b):\n",
    "    self.b = new_b\n",
    "\n",
    "  # Расчет прямого прохождения для нескольких X\n",
    "  def _feedforward(self, X):\n",
    "    # -1; X.shape[0] - количество значений в батче\n",
    "    # W[0].shape[1] - количество входов = net_in\n",
    "    self.a[0] = X.T.reshape(self.W[0].shape[1], -1)\n",
    "    # рассчитываем скрытые и выходной слои\n",
    "    for k in range(self.depth):\n",
    "      # перемножаются W [i (текущий слой), j (предыдущий)] * a[j (количество нейронов), l (количество в батче)]\n",
    "      self.z[k+1] = np.matmul(self.W[k], self.a[k]) + self.b[k]\n",
    "      # Выполняется только для скрытых слоев либо если передан _is_need_func_final\n",
    "      if k != self.depth-1 or self._is_need_func_final:\n",
    "        self.a[k+1] = self.activation_fn(self.z[k+1])\n",
    "      else:\n",
    "        self.a[-1] = self.z[-1]\n",
    "\n",
    "# Расчет локального градиента при обратном распространении ошибок\n",
    "  def _backprop(self, y, batch_size=32):\n",
    "    # TODO сделать delta для выходящего слоя при _is_need_func_final\n",
    "    # a[j, l], y[l, in]\n",
    "    delta = self.error_dfn(self.a[-1], y.T)\n",
    "    for k in range(self.depth-1, 0, -1):\n",
    "      # Идем в обратном порядке. k - текущий слой, k+1 следующий. j - количество нейронов в текущем слое. i - количество нейронов в k+1 слое,\n",
    "      # todo возможно требуется поменять на loss_dfn\n",
    "      if k != self.depth-1:\n",
    "\n",
    "      # f(z[i][l]) * (dot (W[j][i], delta[i][l]) получаем [j][l], так как для W[k].shape(i) = z[k].shape(j)\n",
    "        delta = self.activation_dfn(self.z[k+1]) * np.matmul(self.W[k+1].T, delta)\n",
    "      # dot(delta[j][l], a[l][j]) должны получить dW[i, j]\n",
    "      self.dW[k] = np.matmul(delta, self.a[k].T)\n",
    "      # delta[j][1] sum l\n",
    "      self.db[k] = np.sum(delta, axis=1, keepdims=True)\n",
    "\n",
    "  # simple sgd\n",
    "  def _update_params(self, lr=1e-2):\n",
    "    for k in range(self.depth):\n",
    "      self.W[k] -= lr*self.dW[k]\n",
    "      self.b[k] -= lr*self.db[k]\n",
    "\n",
    "  def train(self, X, y, epochs=1, batch_size=32):\n",
    "    # n = y.shape[0]\n",
    "    # epoch_losses = np.array([])\n",
    "    dataset = list(zip(X, y))\n",
    "    get_X = lambda z: z[0]\n",
    "    get_y = lambda z: z[1]\n",
    "    for i in range(epochs):\n",
    "      rng.shuffle(dataset)\n",
    "\n",
    "      X_batch = np.array([get_X(x) for x in dataset])\n",
    "      y_batch = np.array([get_y(y) for y in dataset])\n",
    "      # for (X_batch, y_batch) in get_batches(dataset, batch_size):\n",
    "      self._feedforward(X_batch)# X_batch)\n",
    "      self._backprop(y_batch)# y_batch)\n",
    "      self._update_params()\n",
    "\n",
    "      # epoch_losses = np.append(epoch_losses, self._compute_loss(X, y))\n",
    "    # return epoch_losses\n",
    "\n",
    "  def predict(self, X):\n",
    "    a = X.T.reshape(self.W[0].shape[1], -1)\n",
    "    # compute hidden and output layers\n",
    "    for i in range(self.depth):\n",
    "      a = np.matmul(self.W[i], a) + self.b[i]\n",
    "      if i != self.depth-1 or self._is_need_func_final:\n",
    "        a = self.activation_fn(a)\n",
    "    return a"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Используем модель"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "(16, 3)"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_arch_test = (3, 16, 1)\n",
    "mlp_test = MLP(net_arch_test, fn=(tanh, dtanh))\n",
    "mlp_test.W[0].shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "X_train = np.array([\n",
    "    [-1, -1, -1],\n",
    "    [-1, -1, 1],\n",
    "    [-1, 1, -1],\n",
    "    [-1, 1, 1],\n",
    "    [1, -1, -1],\n",
    "    [1, -1, 1],\n",
    "    [1, 1, -1],\n",
    "    [1, 1, 1]\n",
    "])\n",
    "y_train = np.array([[-1, 1, -1, 1, -1, 1, -1, -1]]).T"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "(array([[-1, -1, -1],\n        [-1, -1,  1],\n        [-1,  1, -1],\n        [-1,  1,  1],\n        [ 1, -1, -1],\n        [ 1, -1,  1],\n        [ 1,  1, -1],\n        [ 1,  1,  1]]),\n array([[-1],\n        [ 1],\n        [-1],\n        [ 1],\n        [-1],\n        [ 1],\n        [-1],\n        [-1]]))"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "mlp_test.train(X_train, y_train, epochs=500)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Входящие данные\n",
      " [[-1 -1 -1]\n",
      " [-1 -1  1]\n",
      " [-1  1 -1]\n",
      " [-1  1  1]\n",
      " [ 1 -1 -1]\n",
      " [ 1 -1  1]\n",
      " [ 1  1 -1]\n",
      " [ 1  1  1]] [[-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [ 1]\n",
      " [-1]\n",
      " [-1]]\n",
      "Результат:\n",
      " [[-1.00047228]\n",
      " [ 1.02126651]\n",
      " [-1.00729488]\n",
      " [ 0.98170086]\n",
      " [-1.01049138]\n",
      " [ 0.98176718]\n",
      " [-0.98121839]\n",
      " [-0.98976406]]\n",
      "Разница между результатом и y_train:\n",
      " [[0.00047228]\n",
      " [0.02126651]\n",
      " [0.00729488]\n",
      " [0.01829914]\n",
      " [0.01049138]\n",
      " [0.01823282]\n",
      " [0.01878161]\n",
      " [0.01023594]]\n"
     ]
    }
   ],
   "source": [
    "i = [0, 1, 2, 3]\n",
    "res = mlp_test.predict(X_train).T\n",
    "print('Входящие данные\\n',X_train, y_train)\n",
    "print('Результат:\\n',res)\n",
    "print('Разница между результатом и y_train:\\n', abs(res-y_train))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.00031236]] [1]\n"
     ]
    }
   ],
   "source": [
    "print(mlp_test.predict(np.array([ X_train[3]])), y_train[3])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "TODO проверить транспонирование и индексы"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "data": {
      "text/plain": "[array([[ 0.41156718],\n        [-1.49674125],\n        [ 1.69103268]]),\n array([[ 1.7048934 ,  0.58596701, -0.59567012]])]"
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train2 = np.array([-1, 0, 1]).reshape(-1,1)\n",
    "y_train2 = np.array([0, -1, 1]).reshape(-1,1)\n",
    "net_arch_test2 = (1, 3, 1)\n",
    "mlp_test2 = MLP(net_arch_test2, fn=(tanh, dtanh))\n",
    "mlp_test2.W"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "mlp_test2.train(X_train2, y_train2, epochs=1000)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "(3, 3)"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_test2.z[1].shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[-0.00242615, -0.99616654,  0.99736798]])"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_test2.predict(X_train2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
